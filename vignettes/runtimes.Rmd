---
title: "Comments on `bnclassify` package runtimes"
author: "Bojan Mihaljevic, Concha Bielza, Pedro Larranaga"
date: "`r Sys.Date()`"
output: 
  rmarkdown::pdf_document:
    toc: true
    number_sections: true
    keep_tex: true
bibliography: bnclassify.bib  
fontsize: 11pt
vignette: >
  %\VignetteIndexEntry{Comments on runtime}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = FALSE}
knitr::opts_chunk$set(cache = FALSE, autodep = TRUE, collapse = TRUE, comment = "#>"
                      # , fig.height = 3, fig.width = 3
                      )
```

# Prediction  

`bnclassify` implements fast prediction for augmented naive Bayes models with complete data. On the car evaluation data set (see `vignette("bnclassify-introduction")`) it is roughly 100 times faster than  prediction with the `gRain` [@Hojsgaard2012] package. 


```{r complete}
library(bnclassify)
data(car)
nb <- lp(nb('class', car), car, smooth = 0)
gr <- as_grain(nb)
library(microbenchmark)
microbenchmark(bnclassify = predict(nb, car),
               gRain  = gRain::predict.grain(gr, 'class', newdata = car),
               times = 1)
```


# Wrapper algorithms

The wrapper algorithms can be computationally intensive. The following are runtimes for `tan_hc` on a Windows 7, 2.80 GHz, 16 GB RAM machine. 

```{r}
microbenchmark::microbenchmark(
  tan_hc = {set.seed(0); t <- b <- tan_hc('class', car, k = 10, 
                                          epsilon = 0)},
  tan_hc5 = {set.seed(0); t <- b <- tan_hc('class', car, k = 5, 
                                          epsilon = 0)}, 
  times = 1)
```

5-fold cross-validation should take roughly 5 times more than learning.

```{r cv}
tan_hc5 <- tan_hc('class', car, k = 5, epsilon = 0)
tan_hc5 <- lp(tan_hc5, car, smooth = 1)
microbenchmark(tan_hc = {set.seed(0); cv(tan_hc5, car, k = 5)},
               times = 1)
```


With the Soybean data set, which has 36 features, and 562 instances after removing the incomplete ones, `tan_hc` takes about six minutes on the above mentioned Windows 7 machine. 

```{r}
library(mlbench)
data(Soybean)
soy_complete <- na.omit(Soybean)
dim(soy_complete)
```

Commented out for the sake of vignette building time.

```{r}
# microbenchmark::microbenchmark( 
#   bsej = {set.seed(0); tan_hc('Class', soy_complete, k = 5, 
#                                   epsilon = 0)}, 
#   times = 1)
```


# Incomplete data

`bnclassify` uses `gRain` to compute the class posterior of instances with missing values (`NA`s). Even with a single `NA` in a dataset, runtime degrades significantly.


```{r incomplete}
nb <- bnc('nb', 'class', car, smooth = 1)
car_na <- car
car_na[1, 4] <- NA
microbenchmark(predict(nb, car), 
               predict(nb, car_na),
               times = 1)
```

This is especially relevant for wrapper learners, which call prediction during learning. It is therefore probably not a bad idea to use wrappers with incomplete data sets, unless these are rather small. 

# References

